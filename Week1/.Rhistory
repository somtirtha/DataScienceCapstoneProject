library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
on.exit()
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
on.exit()
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
names(train_data)
# clean data
ok = complete.cases(train_data)
train_data = train_data[ok, ]
test_data = test_data[ok, ]
train_data = train_data[ , colSums(is.na(train_data)) == 0]
test_data = test_data[ , colSums(is.na(test_data)) == 0]
classe = train_data$classe
train_exclude = grepl("^X|timestamp|window", names(train_data))
train_data = train_data[, !train_exclude]
train_data = train_data[, sapply(train_data, is.numeric)]
train_data$classe = classe
test_exclude = grepl("^X|timestamp|window", names(test_data))
test_data = test_data[, !test_exclude]
test_data = test_data[, sapply(test_data, is.numeric)]
# belt, forearm, arm, and dumbell
# selection of features
features = names(train_data)
# split the training data into training and validation sets
set.seed(22519) # For reproducibile purpose
inTrain = createDataPartition(train_data$classe, p=0.70, list=F)
training_data = train_data[inTrain, ]
validation_data = train_data[-inTrain, ]
# training a classifier
# do cross validation
rf_model = train(classe ~ ., method="rf", trControl=trainControl(method="cv", 5), ntree=250, data=training_data)
rf_model$finalModel
# predict data on test set
validation_pred = predict(rf_model, validation_data)
# make confusion matrix of the results
confusionMatrix(validation_data$classe, validation_pred)
accuracy = postResample(validation_pred, validation_data$classe)
accuracy
# test on the test data set
test_pred = predict(rf_model, validation_data)
test_pred
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
ll
library(caret)
library(corrplot)
# read the trainig and test sets
train_data = read.csv("pml-training.csv")
test_data = read.csv("pml-testing.csv")
read.csv("pml-training.csv")
str(storm_data)
library(R.utils)
library(reshape2)
library(dplyr)
library(ggplot2)
# Download data
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
bzipFile = 'data/storm_data.csv.bz2'
if (!dir.exists('data')) {
dir.create('data', showWarnings = TRUE, recursive = FALSE, mode = "0755")
}
if (!file.exists(bzipFile)) {
download.file(url, bzipFile, method='wget', quiet = TRUE)
}
csvFile = gsub("[.]bz2$", "", bzipFile)
if (!file.exists(csvFile)) {
# unzipping the data
bunzip2(bzipFile, csvFile)
}
# Reading the data
storm_data = read.csv(csvFile)
library(reshape2)
library(dplyr)
library(ggplot2)
# Download data
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
bzipFile = 'data/storm_data.csv.bz2'
if (!dir.exists('data')) {
dir.create('data', showWarnings = TRUE, recursive = FALSE, mode = "0755")
}
if (!file.exists(bzipFile)) {
download.file(url, bzipFile, method='wget', quiet = TRUE)
}
csvFile = gsub("[.]bz2$", "", bzipFile)
if (!file.exists(csvFile)) {
# unzipping the data
bunzip2(bzipFile, csvFile)
}
# Reading the data
storm_data = read.csv(csvFile)
names(storm_data)
str(storm_data)
storm_data[999,]
storm_data_sub = storm_data[c("EVTYPE","FATALITIES","INJURIES","PROPDMG","PROPDMGEXP","CROPDMG","CROPDMGEXP")]
names(storm_data_sub)
# Creating new variables for total damages to human health and economy
storm_data_sub$HumanDamages = storm_data_sub$FATALITIES + storm_data_sub$INJURIES
storm_data_sub$EcoDamages = storm_data_sub$PROPDMG + storm_data_sub$CROPDMG
# Grouping the data by the event type
storm_data_sub  = storm_data_sub %>% group_by(EVTYPE)
# Creating a new data frame that has info about the total, mean and sd damage
# done per storm event to human health
storm_human_summary = storm_data_sub %>%
summarise(total_human_damage = sum(HumanDamages),
mean_human_damage = round(mean(HumanDamages), 5),
sd_human_damage = sd(HumanDamages)) %>%
filter(total_human_damage > 0)
# Get info for top 10 causes for human damages
storm_human_top_sum = top_n(storm_human_summary, 10, total_human_damage)
storm_human_top_mean = top_n(storm_human_summary, 10, mean_human_damage)
storm_human_top_sum_mean = unique(rbind(storm_human_top_sum, storm_human_top_mean))
storm_human_top_sum_mean = filter(storm_human_top_sum_mean, !is.na(sd_human_damage))
human_damage_plot = ggplot(data = storm_human_top_sum_mean,
aes(x = EVTYPE,
y = log(mean_human_damage),
fill = total_human_damage,
title = "Storm Human Health Damages"))
human_damage_plot + geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle=90, size=8)) +
ylab("log Avg Injury/Fatality") +
scale_fill_continuous(name = "Human Damages") +
geom_errorbar(aes(ymin = log(mean_human_damage)-log(sd_human_damage),
ymax = log(mean_human_damage)+log(sd_human_damage)),
width=.2, position=position_dodge(.9))
# POPULATION HEALTH CONSEQUENCE
# add a new column which adds the injuries and fatalities across events
# storm_data$HumanDamages = storm_data$FATALITIES + storm_data$INJURIES
# names(storm_data)
# events_effects = aggregate(storm_data$HumanDamages,
#                            list(events=storm_data$EVTYPE), sum)
# names(events_effects)
# plot(as.factor(events_effects$events), events_effects$x, type="h",
#      main="Histogram of total fatalities",
#      xlab="Events", ylab="fatalities", col="darkorange2", lwd=10)
# maximum human effect for which storm event?
events_effects[which.max(events_effects$x),]$events
# ECONOMIC CONSEQUENCE
#Variables indicating economic damages are: PROPDMG, CROPDMG
# storm_data_sub$EcoDamages = storm_data_sub$PROPDMG + storm_data_sub$CROPDMG
# names(storm_data_sub)
storm_eco_summary = storm_data_sub %>%
summarise(total_eco_damage = sum(EcoDamages),
mean_eco_damage = round(mean(EcoDamages), 5),
sd_eco_damage = sd(EcoDamages)) %>%
filter(total_eco_damage > 0)
# Get info for top 10 causes for human damages
storm_eco_top_sum = top_n(storm_eco_summary, 10, total_eco_damage)
storm_eco_top_mean = top_n(storm_eco_summary, 10, mean_eco_damage)
storm_eco_top_sum_mean = unique(rbind(storm_eco_top_sum, storm_eco_top_mean))
storm_eco_top_sum_mean = filter(storm_eco_top_sum_mean, !is.na(sd_eco_damage))
eco_damage_plot = ggplot(data = storm_eco_top_sum_mean,
aes(x = EVTYPE,
y = log(mean_eco_damage),
fill = total_eco_damage,
title = "Storm Economical Damages"))
eco_damage_plot + geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle=90, size=8)) +
ylab("Economical Damage") +
scale_fill_continuous(name = "Economic Damages") +
geom_errorbar(aes(ymin = log(mean_eco_damage)-log(sd_eco_damage), ymax = log(mean_eco_damage)+log(sd_eco_damage)),
width=.2, position=position_dodge(.9))
storm_data_sub[1,]
storm_data_sub  = storm_data_sub %>% group_by(EVTYPE) %>%
mutate(
PROPDMG = ifelse(PROPDMGEXP == "K",
PROPDMG,
ifelse(PROPDMG == "M",
PROPDMG * 1000,
PROPDMG * 1000000)),
CROPDMG = ifelse(CROPDMGEXP == "K",
CROPDMG,
ifelse(CROPDMG == "M",
CROPDMG * 1000,
CROPDMG * 1000000)) )
storm_eco_summary = storm_data_sub %>%
summarise(total_eco_damage = sum(EcoDamages),
mean_eco_damage = round(mean(EcoDamages), 5),
sd_eco_damage = sd(EcoDamages)) %>%
filter(total_eco_damage > 0)
# Get info for top 10 causes for human damages
storm_eco_top_sum = top_n(storm_eco_summary, 10, total_eco_damage)
storm_eco_top_mean = top_n(storm_eco_summary, 10, mean_eco_damage)
storm_eco_top_sum_mean = unique(rbind(storm_eco_top_sum, storm_eco_top_mean))
storm_eco_top_sum_mean = filter(storm_eco_top_sum_mean, !is.na(sd_eco_damage))
eco_damage_plot = ggplot(data = storm_eco_top_sum_mean,
aes(x = EVTYPE,
y = log(mean_eco_damage),
fill = total_eco_damage,
title = "Storm Economical Damages"))
eco_damage_plot + geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle=90, size=8)) +
ylab("Economical Damage") +
scale_fill_continuous(name = "Economic Damages") +
geom_errorbar(aes(ymin = log(mean_eco_damage)-log(sd_eco_damage), ymax = log(mean_eco_damage)+log(sd_eco_damage)),
width=.2, position=position_dodge(.9))
storm_data_sub$HumanDamages = storm_data_sub$FATALITIES + storm_data_sub$INJURIES
storm_data_sub$EcoDamages = storm_data_sub$PROPDMG + storm_data_sub$CROPDMG
storm_eco_summary = storm_data_sub %>%
summarise(total_eco_damage = sum(EcoDamages),
mean_eco_damage = round(mean(EcoDamages), 5),
sd_eco_damage = sd(EcoDamages)) %>%
filter(total_eco_damage > 0)
# Get info for top 10 causes for human damages
storm_eco_top_sum = top_n(storm_eco_summary, 10, total_eco_damage)
storm_eco_top_mean = top_n(storm_eco_summary, 10, mean_eco_damage)
storm_eco_top_sum_mean = unique(rbind(storm_eco_top_sum, storm_eco_top_mean))
storm_eco_top_sum_mean = filter(storm_eco_top_sum_mean, !is.na(sd_eco_damage))
eco_damage_plot = ggplot(data = storm_eco_top_sum_mean,
aes(x = EVTYPE,
y = log(mean_eco_damage),
fill = total_eco_damage,
title = "Storm Economical Damages"))
eco_damage_plot + geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle=90, size=8)) +
ylab("Economical Damage") +
scale_fill_continuous(name = "Economic Damages") +
geom_errorbar(aes(ymin = log(mean_eco_damage)-log(sd_eco_damage), ymax = log(mean_eco_damage)+log(sd_eco_damage)),
width=.2, position=position_dodge(.9))
str(storm_data)
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
pkgs <- c("methods","statmod","stats","graphics","RCurl","jsonlite","tools","utils")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/6/R")))
library(h2o)
localH2O = h2o.init()
demo(h2o.kmeans)
getwd
getwd()
install.packages("R.utils")
librbay(R.utils)
#inputFile <- "final/en_US/en_US.twitter.txt"
inputFile <- "sub_dataset.txt"
lines <- readLines(inputFile)
for (i in lines) {
print(length(i))
}
library(R.utils)
#inputFile <- "final/en_US/en_US.twitter.txt"
inputFile <- "sub_dataset.txt"
lines <- readLines(inputFile)
for (i in lines) {
print(length(i))
}
library(R.utils)
#inputFile <- "final/en_US/en_US.twitter.txt"
inputFile <- "sub_dataset.txt"
lines <- readLines(inputFile)
lines <- readLines("sub_dataset.txt")
readLines("sub_dataset.txt")
library(R.utils)
#inputFile <- "final/en_US/en_US.twitter.txt"
# inputFile <- "sub_dataset.txt"
lines <- readLines("sub_dataset.txt")
install.packages("tm")
inputFile <- "../final/en_US/en_US.twitter.txt"
lines <- readLines(inputFile)
love_count <- length(grep("\\<love\\>", lines))
hate_count <- length(grep("\\<hate\\>", lines))
print(love_count/hate_count)
#5
lines[grep("\\<biostats\\>", lines)]
#6
grep("\\<A computer once beat me at chess, but it was no match for me at kickboxing\\>", lines)
getwd()
inputFile <- "final/en_US/en_US.twitter.txt"
lines <- readLines(inputFile)
love_count <- length(grep("\\<love\\>", lines))
hate_count <- length(grep("\\<hate\\>", lines))
print(love_count/hate_count)
#5
lines[grep("\\<biostats\\>", lines)]
#6
grep("\\<A computer once beat me at chess, but it was no match for me at kickboxing\\>", lines)
inputFile <- "final/en_US/en_US.twitter.txt"
lines <- readLines(inputFile)
love_count <- length(grep("\\<love\\>", lines))
hate_count <- length(grep("\\<hate\\>", lines))
print(love_count/hate_count)
#5
lines[grep("\\<biostats\\>", lines)]
#6
grep("\\<A computer once beat me at chess, but it was no match for me at kickboxing\\>", lines)
setwd('/Users/somtirtha/workspace/Programs/Coursera/DataScience/DataScienceCapstoneProject/Week1/')
inputFile <- "../final/en_US/en_US.twitter.txt"
lines <- readLines(inputFile)
love_count <- length(grep("\\<love\\>", lines))
hate_count <- length(grep("\\<hate\\>", lines))
print(love_count/hate_count)
#5
lines[grep("\\<biostats\\>", lines)]
#6
grep("\\<A computer once beat me at chess, but it was no match for me at kickboxing\\>", lines)
